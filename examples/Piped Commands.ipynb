{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bash Generation: Piped Commands\n",
    "\n",
    "In this notebook, I hope to explore concatenating generated bash commands together using a pipe.\n",
    "\n",
    "## Exploring the training data\n",
    "\n",
    "First , I hope to explore how commands are used in the training data and try and see patterns to give us insight into the implementation of piped commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find Path -type f -print0 | xargs -r -0 -I {} grep -F Regex {}',\n",
       " 'find Path -name Regex | xargs -I {} grep -r Regex {}',\n",
       " 'zcat Regex | grep -i Regex',\n",
       " 'zcat Regex | head -n Quantity',\n",
       " 'fold File | wc -l',\n",
       " 'find Path -print0 | xargs -0 -I {} echo {}',\n",
       " 'cd $( find Path -name Regex | xargs -I {} dirname {} )',\n",
       " 'set | grep Regex',\n",
       " 'who | wc -l',\n",
       " 'ls -t -p | grep -v Regex | tail -n +Quantity | xargs -I {} rm -- {}']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('cmds_proccess_train.txt') as fp:\n",
    "    txt = fp.read()\n",
    "    \n",
    "piped_cmds = [cmd for cmd in txt.split('\\n') if '|' in cmd]\n",
    "piped_cmds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A deeper look\n",
    "Let's look a little deeper, particularly into what commands are generally used before and after the pipes, and the average number of pipes used in piped commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of pipes in piped commands is 1.454713493530499\n",
      "Maximum number of pipes in piped commands is 7\n",
      "Total number of piped commands in training data is 3246\n"
     ]
    }
   ],
   "source": [
    "num = m = 0\n",
    "for cmd in piped_cmds:\n",
    "    num += cmd.count('|')\n",
    "    m = max(m, cmd.count('|'))\n",
    "print(f\"Average number of pipes in piped commands is {num / len(piped_cmds)}\")\n",
    "print(f\"Maximum number of pipes in piped commands is {m}\")\n",
    "print(f\"Total number of piped commands in training data is {len(piped_cmds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common utilities before first pipe: \n",
      " [('find', 1721), ('echo', 223), ('cat', 160), ('ls', 99), ('grep', 56)] \n",
      "\n",
      "Most common utilities after first pipe: \n",
      " [('xargs', 1037), ('grep', 443), ('awk', 254), ('sort', 253), ('sed', 218)] \n",
      "\n",
      "Most common utility pairs:\n",
      "(('find', 'xargs'), 956)\n",
      "(('find', 'grep'), 164)\n",
      "(('find', 'sort'), 149)\n",
      "(('find', 'wc'), 97)\n",
      "(('find', 'sed'), 80)\n",
      "(('find', 'awk'), 77)\n",
      "(('find', 'head'), 43)\n",
      "(('ifconfig', 'grep'), 36)\n",
      "(('find', 'cpio'), 35)\n",
      "(('echo', 'tee'), 26)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "first_uts = [cmd.split('|')[0].strip().split(' ')[0] for cmd in piped_cmds]\n",
    "second_uts =[cmd.split('|')[1].strip().split(' ')[0] for cmd in piped_cmds]\n",
    "common_pairings = [(cmd.split('|')[0].strip().split(' ')[0], cmd.split('|')[1].strip().split(' ')[0]) for cmd in piped_cmds]\n",
    "\n",
    "pre_uts = Counter(first_uts)\n",
    "post_uts = Counter(second_uts)\n",
    "pairs = Counter(common_pairings)\n",
    "\n",
    "print(\"Most common utilities before first pipe: \\n\", pre_uts.most_common(5), \"\\n\")\n",
    "print(\"Most common utilities after first pipe: \\n\",post_uts.most_common(5), \"\\n\")\n",
    "print(\"Most common utility pairs:\")\n",
    "for pair in pairs.most_common(10):\n",
    "    print(pair)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Observations\n",
    "\n",
    "It looks like find is most commonly used before the pipe, with xargs, grep and sort most commonly following the pipe, so it makes sense to start with these utilties when creating our pipes. Similar to the rest of the training data, find makes up over half of the piped commands.\n",
    "\n",
    "## Command Generation\n",
    "\n",
    "Our first approach will consist of generating two separate lists of commands, one for find and one for another utiltiy (starting with xargs, grep, and sort) and then concatenate using all possible combinations from the two lists with a pipe in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find\n",
      "syntax not found for find\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mgeorgaklis/Desktop/Fall 2021 Coursework/CS 3860/bash_gen/scraper.py:38: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 38 of the file /Users/mgeorgaklis/Desktop/Fall 2021 Coursework/CS 3860/bash_gen/scraper.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(r.text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xargs\n",
      "grep\n",
      "sort\n"
     ]
    }
   ],
   "source": [
    "from scraper import WebScraper\n",
    "\n",
    "pipe_scraper = WebScraper(utilities=['find', 'xargs', 'grep', 'sort'])\n",
    "\n",
    "pipe_scraper.extract_utilities()\n",
    "pipe_scraper.save_json(map_path='pipe_scrape.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xargs -a File -e Regex -l Number',\n",
       " 'xargs --show-limits -I -i Regex',\n",
       " 'xargs -I',\n",
       " 'xargs -t -0 -p',\n",
       " 'xargs -a File -e Regex -n Number',\n",
       " 'xargs -0 -p --delimiter Regex',\n",
       " 'xargs --delimiter Regex -I',\n",
       " 'xargs --show-limits -e Regex -E',\n",
       " 'xargs --show-limits --version -I',\n",
       " 'xargs -n Number -r -L']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from generator import Generator\n",
    "\n",
    "pipe_gen = Generator(map_path='pipe_scrape.json', utilities=['find', 'xargs', 'grep', 'sort'])\n",
    "pre_pipe_lst = pipe_gen.generate_commands('find')\n",
    "post_pipe_lst = pipe_gen.generate_commands(['xargs', 'grep', 'sort'])\n",
    "post_pipe_lst[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying Commands\n",
    "\n",
    "So now we have two lists, one of commands to put before a pipe, and one of commands to put after the pipe. In order to put less strain on the verification and validation of the commands, we will validate the commands before and after the pipe to see if they run on their own.\n",
    "\n",
    "As we have already run the validation process for find commands, we can simply extract these and use them for our piped command generation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find Path -fprint File -d',\n",
       " 'find Path -links Size -noignore_readdir_race',\n",
       " 'find Path -readable -fprint File -false']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('verified_generic_find_cmds2.txt') as fp:\n",
    "    txt = fp.read()\n",
    "    \n",
    "pre_pipe_lst = txt.split('\\n')\n",
    "pre_pipe_lst[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mix and Match: Creating the Piped Commmands\n",
    "\n",
    "This part is pretty straightforward and involves taking every command in the pre-command list and matching it with every command in the post-command list and adding all the combinationations to one main list. However, since this would create an outrageous number of commands, we will start with 90,000 commands: 300 pre commands matched with 300 post commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find Path -wholename Regex -ilname Regex -noleaf | grep --line-buffered -Z --help Number File',\n",
       " 'find Path -mount -iname Regex -print0 | grep -d Number -v --no-messages Number Number File',\n",
       " 'find Path -xdev -amin Size -writable | grep --no-messages Number -H --exclude-from File Number File',\n",
       " 'find Path -samefile File -links Size -size Size | sort -d -R -m File',\n",
       " 'find Path -daystart -ipath Regex -quit | grep -C Number -x -l Number File',\n",
       " 'find Path -cmin Size -prune -nouser | grep --color Number -l -c Number File']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "piped_cmds = set()\n",
    "\n",
    "for pre_cmd in random.sample(pre_pipe_lst, 300):\n",
    "    for post_cmd in random.sample(post_pipe_lst, 300):\n",
    "        piped_cmds.add(\" | \".join([pre_cmd, post_cmd]))\n",
    "\n",
    "list(piped_cmds)[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pipe_generic.txt', 'w') as fp:\n",
    "    fp.write(\"\\n\".join(piped_cmds))\n",
    "\n",
    "from generator import replace\n",
    "\n",
    "replace(rep_path='rep_map.json', in_path='pipe_generic.txt', out_path='replaced_pipe.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And after running verification on the virtual machine . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21101"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('verified_pipe_find.txt') as fp:\n",
    "    txt = fp.read()\n",
    "    \n",
    "piped = txt.split(\"\\n\")\n",
    "len(piped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse Replcacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import replace\n",
    "replace(rep_path='rep_map.json', in_path='verified_pipe_find.txt', out_path='verified_pipe_generic.txt', reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['find Path -wholename Regex -ilname Regex -noleaf | grep --line-buffered -Z --help Timespan File',\n",
       " 'find Path -samefile File -links Timespan -size Timespan | sort -d -R -m File',\n",
       " 'find Path -nouser -help -ipath Regex | grep -E -o --help Timespan File',\n",
       " 'find Path -print -mtime Timespan -atime Timespan | grep -L --help -T Timespan File',\n",
       " 'find Path -used Timespan -nogroup -fprint0 File | xargs -p -I -i Regex']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('verified_pipe_generic.txt') as fp:\n",
    "    txt = fp.read()\n",
    "    \n",
    "piped = txt.split(\"\\n\")\n",
    "piped[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
